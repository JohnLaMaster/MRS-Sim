{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=”center”><img src=\"./images/github_preview_high_res_v2.png\", width=350></div>\n",
    "\n",
    "- - - "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRS-Sim Framework\n",
    "\n",
    "MRS-Sim is an open-source framework for simulating synthetic, in vivo-like MR spectra. While it was originally developed to facilitate deep learning research, it has many other use cases in spectroscopy. \n",
    "\n",
    "\n",
    "## Model Overview\n",
    "\n",
    "The physics model in this simulator considers every aspect of signal formation and acquistion. This was implemented in a modular way so that not only can highly tailored datasets be simulated for a variety of clinical scenarios, but future developments can be easily implemented. The core model can be described by the following equation:\n",
    "\n",
    "<div align=”center”><img src=\"./images/PM_eqn_overview.png\"></div>\n",
    "\n",
    "### Spectral Components and Artifacts\n",
    "\n",
    "1. $M_n$:&nbsp; Modulation factor for each basis function n\n",
    "2. $d$:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Lorentzian lineshape values, generally 1/T2$_n$ for each basis function n\n",
    "3. $g$:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Gaussian lineshape value. This values reflects the effectiveness of the _B$_0$_ field shimming. This term is insufficient when high susceptibility effects \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; are encountered.\n",
    "4. _f_\\_shift: Frequency shifts. This model uses two types of frequency shifts: moiety-/metabolite-level and global-level are applied to each spectra. \n",
    "5. $A, tc$: Eddy current variables. $A$ is the amplitude, or scale, and $tc$ is the time constant.\n",
    "6. $\\phi_0, \\phi_1$: Phase offsets. They are the zero- and first-order phase offsets.\n",
    "7. B$_0$: 3D model of the B$_0$ magnetic field heterogeneities.\n",
    "8. $SNR, len$: Noise.\n",
    "9. $baseline$: Spectral baseline offset.\n",
    "10. $resH2O$: Residual water signal contribution.\n",
    "11. ${snr}_c$: SNR values for each coil transient.\n",
    "12. ${sens}_c$: Coil sensitivity value.\n",
    "13. $\\Delta f_c$: Frequency drift among the coil transients.\n",
    "14. $\\Delta \\phi_c$: Phase drift among the coil transients.\n",
    "\n",
    "\n",
    "### Physics Model Implementation Details\n",
    "Instead of generating samples sequentially, one-by-one, batches of spectra are simulated using n-dimensional matrices of 1D data. For simplicity's sake, the lineshape and frequency shift values are defined individually for each metabolite, even when a single value is applied. This is a useful design choice because it allows separate values to be applied to the metabolites and nuisance signals (MM/Lip). Additionally, when using individual moiety-level basis functions instead of summed, metabolite-level basis functions, this allows moiety-specific knowledge to be incorporated. This will be discussed in greater detail below in _A priori Knowledge_.\n",
    "\n",
    "\n",
    "### Current Capabilities\n",
    "The following list includes the various types of spectra that can be simulated. As more functionality is added, this list will be updated.\n",
    "1. PRESS, STEAM (coming soon)\n",
    "2. SVS (single voxel)\n",
    "3. Coil-combined\n",
    "4. Multi-coil transients\n",
    "5. Raw, unprocessed with artifacts\n",
    "6. Clean, processed with no remaining artifacts\n",
    "\n",
    "#### _A priori_ Knowledge\n",
    "As additional research is published, this framework can continue to be updated with new advances. Currently, this model can include moiety-level frequency shifts for metabolite moieties that are temperature-sensitive. Additionally, metabolite T2 values for three different brain regions have also been included. These values can be used or sampled randomly. Due to knowledge and research limitations, such information is not available for every metabolite. Eventually, this framework should become a repository for information derived from comprehensive metabolite characterization.\n",
    "\n",
    "#### Planned Future Work\n",
    "1. Difference-edited spectra\n",
    "2. MRSI\n",
    "3. Diffusion spectra\n",
    "4. Spurious echoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial\n",
    "\n",
    "This notebook will walk you through simulating a dataset. If you have any questions, please feel free to post them in the discussion section of the GitHub repository. If you would like to collaborate to develop a dataset instead of simulating your own, you can reach out at john.lamaster (at) tum (dot) de.\n",
    "\n",
    "The actual simulations can be conducted using a single command in the terminal or with several cells at the end of this notebook. The simulations themselves are rather easy to run. The challenging part for the users is to define the config.json file and then set how they want the parameters to be sampled, both of which will be elaborated in the following steps. \n",
    "\n",
    "### Step 1: Define your config.json file\n",
    "\n",
    "In this step, you will define the parameters of the simulation. You can see examples in the /src/config/templates folder. The contents of the config file are broken down into sections that are separated by a blank line so it is easier to read. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block I\n",
    "The first block of entries defines the fundamentals of the clinical scnenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"totalEntries\": 100,\n",
    "\"PM_basis_set\": \"PRESS_30_GE_2000.mat\",\n",
    "\"NIfTIMRS\": true,\n",
    "\"metabolites\": [\"Asc\", \"Asp\", \"Ch\", \"Cr\", \"GABA\", \"Gln\", \"Glu\", \"GPC\", \"GSH\", \"Lac\", \n",
    "                \"mI\", \"NAA\", \"NAAG\", \"PCh\", \"PCr\", \"PE\", \"sI\", \"Tau\", \"MM09\", \"MM12\", \n",
    "                \"MM14\", \"MM17\", \"MM20\", \"Lip09\", \"Lip13\", \"Lip20\"], \n",
    "\"wrt_metab\": \"Cr,PCr\",\n",
    "\"wrt_metab_ratio\": [0.525,0.475],\n",
    "\"snr_metab\": \"Cr,PCr\",\n",
    "\"B0\": 3.0, \n",
    "\"TE\": 30,\n",
    "\"vendor\": \"GE\",\n",
    "\"cropRange\": [0.2,4.2],\n",
    "\"use_covmat\": false, \n",
    "\"spectralwidth\": 2000,\n",
    "\"spectrum_length\": 1024, \n",
    "\"basis_fcn_length\": 2048,\n",
    "\"image_resolution\":    [ 0.5,  0.5,  0.5],\n",
    "\"spectral_resolution\": [10.0, 10.0, 10.0],\n",
    "\"notes\": \"Here you can leave extra notes relevant to the simulation or experiments.\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block II\n",
    "The second block activates different spectral components and artifacts in the model. Here you will use boolean flags to turn artifacts on and off. A few will require numerical values such as _num\\_coils_, _drop\\_prob_, _snr_, and _ppm\\_ref_. Respectively, these define: the number of coil transients to simulate with 1 being coil combined data; the rate of randomly excluding different parts of the model; a list of the SNR min and max ranges; and the reference ppm value, generally the water peak which is 4.65 at 37°C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"apodize\": false,\n",
    "\"broadening\": true,\n",
    "\"lineshape\": \"voigt\",\n",
    "\"b0\": true,\n",
    "\"eddy\": true,\n",
    "\"fids\": false,\n",
    "\"fshift_g\": true,\n",
    "\"fshift_i\": true,\n",
    "\"phi0\": true,\n",
    "\"phi1\": true,\n",
    "\"magnitude\": false,\n",
    "\"noise\": true,\n",
    "\"mm_lip\": false,\n",
    "\"num_coils\": 1,\n",
    "\"coil_fshift\": false,\n",
    "\"coil_phi0\": false,\n",
    "\"coil_sens\": false,\n",
    "\"snr_combo\": \"both\",\n",
    "\"residual_water\": true,\n",
    "\"zero_fill\": false,\n",
    "\"resample\": false,\n",
    "\"drop_prob\": 0.0,\n",
    "\"ppm_ref\": 4.65,\n",
    "\"covmat\": {\"matrix\": null,\n",
    "           \"loc\":    null},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block III\n",
    "\n",
    "The third block is where you define the minimum and maximum parameter ranges. If you leave anything out of this section, default values will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"parameters\": {\n",
    "    \"_d\":              [     3,    10],\n",
    "    \"_g\":              [     5,    20],\n",
    "    \"_dmm\":            [    10,   100],\n",
    "    \"_gmm\":            [     5,    20],\n",
    "    \"f_shift\":         [   -10,    10],\n",
    "    \"phi0\":            [  -0.1,   0.1], \n",
    "    \"phi1\":            [ -0.05,  0.05], \n",
    "    \"b0_dir\":          [    -5,    15],\n",
    "    \"ppm_ref\":                    4.65, \n",
    "    \"snr_min\":         [    10,    20], \n",
    "    \"b0\":              [   150,   200], \n",
    "    \"coil_sens\":       [     0,     2],\n",
    "    \"coil_fshift\":     [   -20,    20],\n",
    "    \"coil_phi0\":       [   -15,    15],\n",
    "    \"eddyCurrents_A\":  [   1.0,  10.0],\n",
    "    \"eddyCurrents_tc\": [  0.02,   0.3],\n",
    "    \"asc\":             [   0.0,  0.16],\n",
    "    \"asp\":             [   0.0,  0.16],\n",
    "    \"ch\":              [   0.0,  0.20],\n",
    "    \"gaba\":            [   0.0,  0.90],\n",
    "    \"glc\":             [   0.0,  0.23],\n",
    "    \"gln\":             [   0.0,  0.42],\n",
    "    \"glu\":             [   0.0,  3.00],\n",
    "    \"gly\":             [   0.0,  0.50],\n",
    "    \"gpc\":             [   0.0,  0.44],\n",
    "    \"gsh\":             [   0.0,  0.18],\n",
    "    \"lac\":             [   0.0,  0.04],\n",
    "    \"mi\":              [   0.0,  0.90],\n",
    "    \"naa\":             [   0.0,  3.50],\n",
    "    \"naag\":            [   0.0,  0.65],\n",
    "    \"pch\":             [   0.0,  0.22],  \n",
    "    \"pcr\":             [   0.3,   1.0],\n",
    "    \"pe\":              [   0.0,  0.40],\n",
    "    \"si\":              [   0.0,  0.80],\n",
    "    \"tau\":             [   0.0,  0.22],\n",
    "    \"mm09\":            [   0.0,  15.0],\n",
    "    \"mm12\":            [   0.0,  15.0],\n",
    "    \"mm14\":            [   0.0,  15.0],\n",
    "    \"mm17\":            [   0.0,  15.0],\n",
    "    \"mm20\":            [   0.0,  15.0],\n",
    "    \"lip09\":           [   0.0,  15.0],\n",
    "    \"lip13\":           [   0.0,  15.0],\n",
    "    \"lip20\":           [   0.0,  15.0]\n",
    "},"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocks IV & V\n",
    "\n",
    "The fourth and fifth blocks are used for defining the baseline offset and the residual water contribution. In general, you should not need to modify these dictionaries. Another notebook will be included in this repo that explores the effects of the parameters for these offset simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"baseline_cfg\": {\n",
    "    \"start\":           [            0],\n",
    "    \"end\":             [            0],\n",
    "    \"upper\":           [            1],\n",
    "    \"lower\":           [           -1],\n",
    "    \"std\":             [  0.05,  0.20],\n",
    "    \"window\":          [  0.15,   0.3],\n",
    "    \"pt_density\":          128,\n",
    "    \"cropRange\":       [  -1.6,   8.5],\n",
    "    \"scale\":           [     1,   1.0],\n",
    "    \"drop_prob\":           0.0\n",
    "},\n",
    "    \n",
    "\"resWater_cfg\": {\n",
    "    \"upper\":           [     0,     1],\n",
    "    \"lower\":           [     0,     1],\n",
    "    \"std\":             [   0.2,  0.40],\n",
    "    \"window\":          [         0.01],\n",
    "    \"pt_density\":         1204,\n",
    "    \"cropRange\":       [   4.4,   4.9],\n",
    "    \"prime\":              0.15,\n",
    "    \"scale\":           [  0.05,  0.20],\n",
    "    \"drop_prob\":           0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the parameter sampling scheme\n",
    "This section of code is used to define the sampling distributions for the parameters.The only code that should be modified will be inside this _sample()_ function. The template files have been documented explaining what types of changes need to go where. Below is an example that is also well-documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(inputs):\n",
    "    # Do NOT change the following line!\n",
    "    config, resWater_cfg, baseline_cfg, pm, l, ind, p, totalEntries = inputs\n",
    "\n",
    "    # Sample parameters from a uniform distribution - deep learning application\n",
    "    params = torch.ones((totalEntries, ind['overall'][-1]+1)).uniform_(0,1)\n",
    "    \n",
    "    # normalization converts the range from [0,1) to [0,1].\n",
    "    params = normalize(params, dims=-1) \n",
    "    \n",
    "    # Quantify parameters\n",
    "    params = pm.quantify_params(params)\n",
    "    \n",
    "    '''\n",
    "    This next section of code will need to be customized for your own implementations.\n",
    "    '''\n",
    "\n",
    "    # All metabolite values are ratios wrt some other metabolite or group of metabolites.\n",
    "    # Therefore, the reference metab or pair/group will always sum to 1.0\n",
    "    if len(config.wrt_metab.split(','))==1: wrt_metab_ratio = [1]\n",
    "    for m, v in zip(config.wrt_metab.split(','),wrt_metab_ratio):\n",
    "        assert(m in config.metabolites)\n",
    "        params[:,ind[m.lower()]].fill_(v)\n",
    "    \n",
    "    '''\n",
    "    The next section of code is used to drop some parameters from each spectrum for deep learning applications.\n",
    "    Should you want to use different distributions for some of the parameters, the following can be used as a \n",
    "    guide. Defining different distributions can be done before OR after quantifying the parameters.\n",
    "    '''\n",
    "    print('>>> Line Broadening')\n",
    "    keys, g = ind.keys(), 0\n",
    "    for k in keys: g += 1 if 'mm' in k else 0\n",
    "    for k in keys: g += 1 if 'lip' in k else 0\n",
    "\n",
    "    # Drop Lorentzian (D) from some metabolites\n",
    "    if config.lineshape in ['voigt','lorentzian']:\n",
    "        for n in ind['d']:\n",
    "            sign = torch.tensor([True if torch.rand([1]) > p else False for _ in range(params.shape[0])])\n",
    "            params[sign,n].fill_(0.)\n",
    "    else:\n",
    "        for n in ind['d']: params[:,n].fill_(0.0)\n",
    "        \n",
    "    # One Gaussian value is used for metabolites and the other is used for MM/Lip - but only 2 values!\n",
    "    # Should an additional group be separated, this and the pm.initialize() code will need to be updated.\n",
    "    if config.lineshape in ['voigt','gaussian']:\n",
    "        for n in ind['g']:\n",
    "            if n==0 || n==int(l-g-1):\n",
    "                sign = torch.tensor([True if torch.rand([1]) > p else False for _ in range(params.shape[0])])\n",
    "                params[sign,n].fill_(0.)\n",
    "\n",
    "            if n>0 and n<l-g-1:\n",
    "                params[:,n] = params[:,ind['g'][0]].clone()\n",
    "            if n>l-g-1:\n",
    "                params[:,n] = params[:,ind['g'][int(l-g-1)]].clone()\n",
    "    else:\n",
    "        for n in ind['g']: \n",
    "            params[:,n].fill_(0.0)\n",
    "            \n",
    "    \n",
    "    print('>>> Transients')\n",
    "    factors = torch.distributions.normal.Normal(1,0.25).sample(params[:,ind['coil_snr']].shape)\n",
    "    params[:,ind['coil_snr']] = factors\n",
    "    # Values are sampled from a Gaussian mu=1, min/max=0/2\n",
    "    # The linear SNR is calculated and scaled based on the number of transients\n",
    "    # Then the linear SNR is scaled about 1.0 so mu = lin_snr\n",
    "    if config.coil_sens:\n",
    "        print('>>> Coil Sensitivities')\n",
    "        params[:,ind['coil_sens']] = torch.distributions.normal.Normal(1,0.5).sample(params[:,ind['coil_sens']].shape).clamp(min=0.0,max=2.0)\n",
    "        sign = torch.tensor([True if torch.rand([1]) > p else False for _ in range(params.shape[0])])\n",
    "        params[sign,ind['coil_sens']].fill_(1.0)\n",
    "\n",
    "    if config.coil_fshift:\n",
    "        print('>>> Coil Frequency Drift')\n",
    "        factors = torch.distributions.normal.Normal(1,0.25).sample(params[:,ind['coil_fshift']].shape)\n",
    "        params[:,ind['coil_fshift']] = factors * params[:,ind['coil_fshift']][0]\n",
    "        sign = torch.tensor([True if torch.rand([1]) > p else False for _ in range(params.shape[0])])\n",
    "        params[sign,ind['coil_fshift']].fill_(0.0)\n",
    "\n",
    "    if config.coil_phi0:\n",
    "        print('>>> Coil Phase Drift')\n",
    "        factors = torch.distributions.normal.Normal(1,0.25).sample(params[:,ind['coil_phi0']].shape)\n",
    "        params[:,ind['coil_phi0']] = factors * params[:,ind['coil_phi0']][0]\n",
    "        sign = torch.tensor([True if torch.rand([1]) > p else False for _ in range(params.shape[0])])\n",
    "        params[sign,ind['coil_phi0']].fill_(0.0)\n",
    "\n",
    "    '''\n",
    "    If certain parts of the model are turned off, then their values should be zeroed out.\n",
    "    '''\n",
    "    if not config.b0:\n",
    "        params[:,ind['b0']].fill_(0.0)\n",
    "        for n in ind['b0_dir']: params[:,n].fill_(0.0)\n",
    "    # D is dealt with above\n",
    "    if not config.eddy: \n",
    "        for n in ind['ecc']: params[:,n].fill_(0.0)\n",
    "    if not config.fshift_g: params[:,ind['f_shift']].fill_(0.0)\n",
    "    if not config.fshift_i:\n",
    "        for n in ind['f_shifts']: params[:,n].fill_(0.0)\n",
    "    # G is dealt with above\n",
    "    if not config.noise: params[:,ind['snr']].fill_(0.0)\n",
    "    if not config.phi0: params[:,ind['phi0']].fill_(0.0)\n",
    "    if not config.phi1: params[:,ind['phi1']].fill_(0.0)\n",
    "    if config.num_coils<=1:\n",
    "        params[:,ind['coil_snr']].fill_(0.0)\n",
    "        params[:,ind['coil_sens']].fill_(0.0)\n",
    "        params[:,ind['coil_fshift']].fill_(0.0)\n",
    "        params[:,ind['coil_phi0']].fill_(0.0)\n",
    "    \n",
    "    \n",
    "    return config, resWater_cfg, baseline_cfg, pm, l, ind, p, totalEntries, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _sample()_ function defined above should be included in the _custom\\_dataset.py_ file that is used to run the simulation. The template for such a file is below. The _sample()_ function should be included after the imports and before ```if __name__=='__main__':```. Save this file in the main folder of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from src.aux import normalize\n",
    "from src.main_fcns import _save, prepare, simulate\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "# Define sample function\n",
    "# The sample function described above should be copied and pasted here.\n",
    "# def sample(input):\n",
    "#     ...\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--savedir', type=str, default='./dataset/30ms_publication')\n",
    "    parser.add_argument('--batchSize', type=int, default=10000)\n",
    "    parser.add_argument('--stepSize', type=int, default=10000)\n",
    "    parser.add_argument('--parameters', type=str, default=None, help='Path to .mat file with pre-sampled parameters')\n",
    "    parser.add_argument('--config_file', type=str, default='./src/configurations/debug_new_init.json')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    os.makedirs(args.savedir, exist_ok=True)\n",
    "\n",
    "    # Simulate\n",
    "    if isinstance(args.parameters, str):\n",
    "        from aux import load_parameters\n",
    "        sampled = load_parameters(args.parameters, prepare(args.config_file))\n",
    "    else:\n",
    "        sampled = sample(prepare(args.config_file))\n",
    "\n",
    "    path = simulate(sampled,args=args)\n",
    "\n",
    "    io.savemat(path+'_sampled_parameters.mat', mdict={'params': sampled[-1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Running the simulations\n",
    "Once the config.json file and the custom\\_dataset.py have been developed, it is time to run the simulation. There are two main options for running the simulation: command line and jupyter-notebook. \n",
    "\n",
    "\n",
    "#### Command Line\n",
    "The _savedir_ and _config\\_file_ arguments can be save in the file above or given in the command line. If they are saved in the file, the following command can be used: \n",
    "\n",
    "```> python3 custom_dataset.py```\n",
    "\n",
    "If they are not saved in the file itself, the following command can be use:\n",
    "\n",
    "```> python3 custom_dataset.py --savedir \"./dataset/custom_dataset\" --config_file \"./src/config/config.json\"```\n",
    "\n",
    "#### Jupyter-Notebook\n",
    "If you prefer to use a Juypter-Notebook, you can update the code in the _Simulation Notebook.ipynb_ as described above, and then click _Run_ in each of the cells in the order in which they appear."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9a",
   "language": "python",
   "name": "python3.9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
