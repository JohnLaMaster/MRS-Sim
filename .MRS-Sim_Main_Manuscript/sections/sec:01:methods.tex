\section{Methods}\label{sec:Methods}
\subsection{Physics Model Algorithm}
In literature, various MRS physics models have been proposed to simulate brain spectra. They begin with simulated basis functions that are assumed to have been simulated using appropriate pulse sequence parameters for the scenario of interest. These metabolite basis functions are then modulated by scaling factors that indicate their underlying concentrations. Most models then apply a simple Lorentzian lineshape.\cite{Hatami, Das2018a, Das2018} Phase offsets\cite{Das2018,Iqbal2018a} and frequency shifts\cite{Hatami} can optionally be applied. Finally, some type of broad baseline is typically added. These models are simple and do not capture the full complexity of clinical data. Additionally, they often include non-public components such as baselines, macromolecules, and lipid signals that are extracted from private datasets.

To maximize generalizability and usefulness, the data simulator should comprehensively model known spectral components, which were identified through a review of state-of-the-art fitting techniques and currently available fitting algorithms. These spectral components allow the model to account for a large variety of scenarios and artifacts. The physics model proposed in this work is described by the following set of equations:
\input{equations/eqn:physics_model.tex}
where $N$ is the whole set of metabolites being modeled, $M_n$ is the scaling factor for metabolite $n$, the Lorentzian variable $d_n$ and the Gaussian variable $g_n$ combine to define a Voigt lineshape, $t$ is time, and $\Delta f_n$ is the metabolite-specific frequency shift. Global zero- and first-order phase offsets are added using $\phi_0$ and $\phi_1$ while eddy current effects are described using two variables as a function of time $t$: the amplitude, $A_0$, and the time constant, $tc_0$. In lieu of the Gaussian term, imperfect shimming and severe lineshape distortions associated with large susceptibility effects can be applied using $\Delta\omega_r$, which is the modeled $B_0$ at location $r$ inside the voxel of interest. $snr_0$ is the desired SNR of the spectrum, while $baseline$ and $resH_2O$ are semi-parameterized signals that account for the broad baseline offset and the poorly defined residual water contributions. If coil-combined FIDs are required, then the simulation can stop after Eqn. \ref{eqn:PM:step1}. Multi-coil acquisitions are simulated in Eqn. \ref{eqn:PM:step2} in which the operator $\mathcal{C}oil$ generates $C$ coil transients and applies a distribution of SNR values and coil weights using $snr_c$ and $sens_c$. Frequency drifts and phase drifts are then added using $\Delta f_c$ and $\Delta \phi_c$, respectively. When necessary, Eqn. \ref{eqn:PM:step3} can apply apodization using $T_L$ in Hz and the FIDs can be zero-filled to length $len$. Then the Fourier transform $\mathcal{F}$ can convert the FIDs to the frequency domain. Each term is discussed in more detail below. 

\input{sections/subsec:02:PM.tex}

\subsection{Exporting Data}\label{subsec:exporting data}
The default export file format is .mat. These files include the data, spectral fits, simulation parameters, baseline offsets, and quantification results. To facilitate using the simulated spectra in various software packages, they are also exported in the NIfTI-MRS format\cite{Clarke2022}.
 
\subsection{Fitting Parameter Analysis}\label{subsec:Fitting Parameter Analysis}
The process of simulating a new dataset requires careful consideration of various factors, including the selection of appropriate parameter ranges and distributions. The optimal customization of these parameters depends on the intended use and application of the dataset. For instance, deep learning-based quantification models benefit from independent, uniform distributions that include all values the model will be expected to encounter. When validating a traditional spectral fitting model that includes soft constraints, it is crucial to incorporate those constraints when defining the parameter distributions. This ensures that the simulated dataset accurately reflects the underlying distribution of the target dataset. 

To mimic an in vivo dataset, accurate descriptions of clinical fitting parameters are crucially important. In collaboration with Osprey, it is now possible to export the spectral fitting parameters after quantification. Tools in this framework can then load the exported files and prepare the data for further analysis. Currently, this framework uses the python library Fitter\cite{Cokelaer2019} to identify the best fitting probability distribution for every parameter. \textit{A priori} knowledge, either from prior knowledge or data exploration, can narrow down the search range and speed up the analysis. The outputs for each parameter include evaluation metrics for the best performing distributions as well as a numerical characterization of the best fitting distribution.
 
\subsubsection{Recommendations}
The authors generally recommend that simulations include all relevant artifacts unless there is a specific reason to exclude them. A simulated dataset should include all phenomena that are expected to be encountered when the final work is deployed. Even highly accurate post-processing techniques have limitations and biases and leave some residue of the corrected artifacts. To ensure consistency between the simulated and clinical data, the artifacts should be included in the simulations and removed via the usersâ€™ own fitting protocols.  

Although not recommended, residual artifacts and post-processing techniques can be included in the simulations. Phase and frequency corrections can be simulated by applying a minimal offset during the initial simulation, which can be implemented in the parameter sampling protocol. Similarly, eddy currents can be scaled down by minimizing the sampled amplitudes. While not part of the acquisition protocol, apodization and zero filling are also possible. Apodization improves the SNR by multiplying the FID by a filter function, typically an exponential decay function or a Lorenztian-to-Gaussian transform. This framework implements an exponential decay as a function of time, $t$, and $T_L$ which defines the amount of apodization in Hz. Zero filling simply pads the FID with zeros to a defined length before the Fourier transform.

\subsection{Code}
This repository was written in PyTorch 1.11.0 and Python 3.9.7. Since this framework generates batches of spectra instead of individual spectra sequentially, a simulation batch size needs to be specified which will be affected by the spectral length and complexity of the simulations. As long as the batch size is set appropriately given the users' amount of RAM, this framework can be employed on standard computers without any special hardware. After publication, the repository will be available on GitHub, at \todo{https://www.github.com/REPOSITORY}, and MRSHub.

